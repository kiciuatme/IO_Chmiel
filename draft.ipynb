{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Snippets:\n",
    "`(pvio)> python3 -m pip install -r reqs.txt` - zaktualizuj biblioteki pyenv'a"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOAD `((N1 x *.jpg; N2 x *.csv[label_x_ref,*labels_cls]) -> (dy: pandas.dataframe[label_x_ref,*labels_cls], dx: {dy[label_x_ref]: ndarray[N3, *data_x_target_res, 3]]}))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read stats:\n",
      "    # entries ok: 193\n",
      "    # excess X: 0\n",
      "    # excess Y: 0\n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>MEL</th>\n",
       "      <th>NV</th>\n",
       "      <th>BCC</th>\n",
       "      <th>AKIEC</th>\n",
       "      <th>BKL</th>\n",
       "      <th>DF</th>\n",
       "      <th>VASC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_0034321</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0034322</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_0034323</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISIC_0034324</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISIC_0034325</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>ISIC_0034519</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>ISIC_0034520</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>ISIC_0034521</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>ISIC_0034522</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>ISIC_0034523</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>193 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            image  MEL   NV  BCC  AKIEC  BKL   DF  VASC\n",
       "0    ISIC_0034321  0.0  1.0  0.0    0.0  0.0  0.0   0.0\n",
       "1    ISIC_0034322  0.0  1.0  0.0    0.0  0.0  0.0   0.0\n",
       "2    ISIC_0034323  0.0  0.0  1.0    0.0  0.0  0.0   0.0\n",
       "3    ISIC_0034324  0.0  1.0  0.0    0.0  0.0  0.0   0.0\n",
       "4    ISIC_0034325  0.0  1.0  0.0    0.0  0.0  0.0   0.0\n",
       "..            ...  ...  ...  ...    ...  ...  ...   ...\n",
       "188  ISIC_0034519  0.0  1.0  0.0    0.0  0.0  0.0   0.0\n",
       "189  ISIC_0034520  0.0  1.0  0.0    0.0  0.0  0.0   0.0\n",
       "190  ISIC_0034521  0.0  0.0  0.0    0.0  1.0  0.0   0.0\n",
       "191  ISIC_0034522  0.0  1.0  0.0    0.0  0.0  0.0   0.0\n",
       "192  ISIC_0034523  0.0  0.0  1.0    0.0  0.0  0.0   0.0\n",
       "\n",
       "[193 rows x 8 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "data_x_path_regex = r\"../ISIC2018_Task3_Validation_Input/*.jpg\"\n",
    "data_y_path_regex = r\"../ISIC2018_Task3_Validation_GroundTruth/ISIC2018_Task3_Validation_GroundTruth.csv\"\n",
    "data_x_target_res = (450, 600)\n",
    "label_x_ref = 'image'\n",
    "labels_cls = ['MEL', 'NV', 'BCC', 'AKIEC', 'BKL', 'DF', 'VASC']\n",
    "\n",
    "# preprocess X data\n",
    "def data_x_loader(data_x_path):\n",
    "    x = data_x_path\n",
    "    x = cv2.imread(x)\n",
    "    x = cv2.resize(x, data_x_target_res)\n",
    "    x = cv2.cvtColor(x, cv2.COLOR_BGR2YCrCb)\n",
    "    return x\n",
    "\n",
    "def load(data_x_path_regex, data_y_path_regex):\n",
    "    # read & merge Y data\n",
    "    data_y_paths = glob.glob(data_y_path_regex)\n",
    "    assert data_y_paths.__len__() > 0\n",
    "    dy_full = pd.concat([pd.read_csv(data_y_path) for data_y_path in data_y_paths])\n",
    "\n",
    "    # read & filter_out by Y & map X data\n",
    "    data_x_paths = glob.glob(data_x_path_regex)\n",
    "    map_ref2path_full = {ref: next((dxp for dxp in data_x_paths if ref in dxp), None) for ref in dy_full['image']}\n",
    "    map_ref2path = {ref: data_x_path for ref, data_x_path in map_ref2path_full.items() if data_x_path is not None}\n",
    "    dx = {ref: data_x_loader(data_x_path) for ref, data_x_path in map_ref2path.items()}\n",
    "\n",
    "    # filter out Y entries that dont have X entry\n",
    "    dy = dy_full.loc[dy_full['image'].isin(map_ref2path.keys())]\n",
    "\n",
    "    print(\n",
    "    f\"\"\"Read stats:\n",
    "    # entries ok: {dy.__len__()}\n",
    "    # excess X: {map_ref2path_full.__len__() - map_ref2path.__len__()}\n",
    "    # excess Y: {dy_full.__len__() - dy.__len__()}\n",
    "    \"\"\")\n",
    "    return dx, dy\n",
    "\n",
    "dx, dy = load(data_x_path_regex, data_y_path_regex)\n",
    "dy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAIN TEST SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# from sklearn.decomposition import sparse_encode\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelBinarizer\n",
    "\n",
    "ohe = OneHotEncoder(sparse=False)\n",
    "# ohe.fit([[label_cls, lix] for lix, label_cls in enumerate(labels_cls)])\n",
    "ohe.fit(np.reshape(labels_cls, (-1, 1)))\n",
    "# ohe.fit_transform(labels_cls)\n",
    "# print(ohe.get_feature_names_out())\n",
    "\n",
    "\n",
    "tts_factor = .2\n",
    "\n",
    "def data2clf_data(dy_selected, dx):\n",
    "    pass\n",
    "\n",
    "sparse = ohe.inverse_transform(dy[labels_cls])\n",
    "dyt, dys = train_test_split(dy, test_size=tts_factor, stratify=sparse)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN (control case) `(dx, dy) -> clf`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ohe.inverse_transform(dy[labels_cls].to_numpy())\n",
    "ohe.transform(ohe.inverse_transform(dy[labels_cls]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sparse_encode() missing 1 required positional argument: 'dictionary'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\krism\\Desktop\\semestr10\\IO\\IO_Chmiel\\draft.ipynb Cell 8\u001b[0m in \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/krism/Desktop/semestr10/IO/IO_Chmiel/draft.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# [y for y in dy['image']]\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/krism/Desktop/semestr10/IO/IO_Chmiel/draft.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# data_x_paths\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/krism/Desktop/semestr10/IO/IO_Chmiel/draft.ipynb#X10sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# dy.at[8, 'DF'] = dx[1]\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/krism/Desktop/semestr10/IO/IO_Chmiel/draft.ipynb#X10sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# dx\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/krism/Desktop/semestr10/IO/IO_Chmiel/draft.ipynb#X10sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# import keras\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/krism/Desktop/semestr10/IO/IO_Chmiel/draft.ipynb#X10sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m sparse_encode([[\u001b[39m0\u001b[39;49m, \u001b[39m1\u001b[39;49m], [\u001b[39m1\u001b[39;49m, \u001b[39m0\u001b[39;49m]])\n",
      "\u001b[1;31mTypeError\u001b[0m: sparse_encode() missing 1 required positional argument: 'dictionary'"
     ]
    }
   ],
   "source": [
    "# [y for y in dy['image']]\n",
    "# data_x_paths\n",
    "# dy.at[8, 'DF'] = dx[1]\n",
    "# np.where(dy['image'][0] in data_x_paths)\n",
    "# for a, in map(str.__contains__, dy['image'], data_x_paths):\n",
    "#     print(a) \n",
    "# dy.loc[dy['image'].isin(['ISIC_0034321', ''])]\n",
    "# map_ref2path.keys()\n",
    "# dx\n",
    "# import keras\n",
    "# sparse_encode([[0, 1], [1, 0]])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pvio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
