{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Snippets:\n",
    "* `(pyvenv)> python3 -m pip freeze > reqs.txt` - wyeksportuj bib pyvenv'a\n",
    "* `(pyvenv)> python3 -m pip install -r reqs.txt` - zaktualizuj biblioteki pyvenv'a"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOAD `((c x *.jpg; c x *.csv[label_x_ref,*labels_cls]) -> (dx, dy, dl))`\n",
    "\n",
    "params:\n",
    "* `data_x_path_regex`     - regex do plików z input'em (obrazów)\n",
    "* `data_y_path_regex`     - regex do csv-ek z output'em (ground of truth), load merguje je ze sobą\n",
    "* `data_x_target_shape`   - standaryzacja obrazów\n",
    "* `label_x_ref`           - kolumna w pandas'ie z hashami do obrazów\n",
    "* `labels_cls`            - kolumny w pandas'ie z kategoriami klasyfikacji\n",
    "\n",
    "output:\n",
    "* `dx: {dy[label_x_ref]: ndarray[c, *data_x_target_shape]]}` - słownik z obrazami hashowany `label_x_ref`\n",
    "* `dy: pandas.dataframe[label_x_ref,*labels_cls]` - \n",
    "* `dl: Tuple[string]` -  lista kategorii po filtracji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV found:\n",
      "    ../ISIC2018_Task3_Training_GroundTruth/ISIC2018_Task3_Training_GroundTruth.csv\n",
      "Read stats:\n",
      "    # entries ok: 10015\n",
      "    # excess X: 0\n",
      "    # excess Y: 0\n",
      "    # excess L: 0  \n",
      "# samples/label:\n",
      "MEL      1113\n",
      "NV       6705\n",
      "BCC       514\n",
      "AKIEC     327\n",
      "BKL      1099\n",
      "DF        115\n",
      "VASC      142\n",
      "dtype: int32\t\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>MEL</th>\n",
       "      <th>NV</th>\n",
       "      <th>BCC</th>\n",
       "      <th>AKIEC</th>\n",
       "      <th>BKL</th>\n",
       "      <th>DF</th>\n",
       "      <th>VASC</th>\n",
       "      <th>path</th>\n",
       "      <th>sparse</th>\n",
       "      <th>categorical</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_0024306</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>../ISIC2018_Task3_Training_Input/ISIC_0024306.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>NV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0024307</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>../ISIC2018_Task3_Training_Input/ISIC_0024307.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>NV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_0024308</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>../ISIC2018_Task3_Training_Input/ISIC_0024308.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>NV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISIC_0024309</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>../ISIC2018_Task3_Training_Input/ISIC_0024309.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>NV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISIC_0024310</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>../ISIC2018_Task3_Training_Input/ISIC_0024310.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>MEL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10010</th>\n",
       "      <td>ISIC_0034316</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>../ISIC2018_Task3_Training_Input/ISIC_0034316.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>MEL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10011</th>\n",
       "      <td>ISIC_0034317</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>../ISIC2018_Task3_Training_Input/ISIC_0034317.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>MEL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10012</th>\n",
       "      <td>ISIC_0034318</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>../ISIC2018_Task3_Training_Input/ISIC_0034318.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>BKL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10013</th>\n",
       "      <td>ISIC_0034319</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>../ISIC2018_Task3_Training_Input/ISIC_0034319.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>NV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10014</th>\n",
       "      <td>ISIC_0034320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>../ISIC2018_Task3_Training_Input/ISIC_0034320.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>NV</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10015 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              image  MEL   NV  BCC  AKIEC  BKL   DF  VASC  \\\n",
       "0      ISIC_0024306  0.0  1.0  0.0    0.0  0.0  0.0   0.0   \n",
       "1      ISIC_0024307  0.0  1.0  0.0    0.0  0.0  0.0   0.0   \n",
       "2      ISIC_0024308  0.0  1.0  0.0    0.0  0.0  0.0   0.0   \n",
       "3      ISIC_0024309  0.0  1.0  0.0    0.0  0.0  0.0   0.0   \n",
       "4      ISIC_0024310  1.0  0.0  0.0    0.0  0.0  0.0   0.0   \n",
       "...             ...  ...  ...  ...    ...  ...  ...   ...   \n",
       "10010  ISIC_0034316  1.0  0.0  0.0    0.0  0.0  0.0   0.0   \n",
       "10011  ISIC_0034317  1.0  0.0  0.0    0.0  0.0  0.0   0.0   \n",
       "10012  ISIC_0034318  0.0  0.0  0.0    0.0  1.0  0.0   0.0   \n",
       "10013  ISIC_0034319  0.0  1.0  0.0    0.0  0.0  0.0   0.0   \n",
       "10014  ISIC_0034320  0.0  1.0  0.0    0.0  0.0  0.0   0.0   \n",
       "\n",
       "                                                    path  sparse categorical  \n",
       "0      ../ISIC2018_Task3_Training_Input/ISIC_0024306.jpg       1          NV  \n",
       "1      ../ISIC2018_Task3_Training_Input/ISIC_0024307.jpg       1          NV  \n",
       "2      ../ISIC2018_Task3_Training_Input/ISIC_0024308.jpg       1          NV  \n",
       "3      ../ISIC2018_Task3_Training_Input/ISIC_0024309.jpg       1          NV  \n",
       "4      ../ISIC2018_Task3_Training_Input/ISIC_0024310.jpg       0         MEL  \n",
       "...                                                  ...     ...         ...  \n",
       "10010  ../ISIC2018_Task3_Training_Input/ISIC_0034316.jpg       0         MEL  \n",
       "10011  ../ISIC2018_Task3_Training_Input/ISIC_0034317.jpg       0         MEL  \n",
       "10012  ../ISIC2018_Task3_Training_Input/ISIC_0034318.jpg       4         BKL  \n",
       "10013  ../ISIC2018_Task3_Training_Input/ISIC_0034319.jpg       1          NV  \n",
       "10014  ../ISIC2018_Task3_Training_Input/ISIC_0034320.jpg       1          NV  \n",
       "\n",
       "[10015 rows x 11 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "data_x_path_regex = r\"../ISIC2018_Task3_Training_Input/*.jpg\"\n",
    "data_y_path_regex = r\"../ISIC2018_Task3_Training_GroundTruth/ISIC2018_Task3_Training_GroundTruth.csv\"\n",
    "data_x_target_shape = (600, 450, 3)\n",
    "label_x_ref = 'image'\n",
    "labels_cls = ['MEL', 'NV', 'BCC', 'AKIEC', 'BKL', 'DF', 'VASC']\n",
    "label_x_path = 'path'\n",
    "label_y_sparse = 'sparse'\n",
    "label_y_cat = 'categorical'\n",
    "\n",
    "# preprocess X data\n",
    "data_x_target_res = data_x_target_shape[:2]\n",
    "# def data_x_loader(data_x_path):\n",
    "#     x = data_x_path\n",
    "#     x = cv2.imread(x)\n",
    "#     x = cv2.resize(x, data_x_target_res)\n",
    "#     x = cv2.cvtColor(x, cv2.COLOR_BGR2YCrCb)\n",
    "#     return x\n",
    "\n",
    "def load(data_x_path_regex, data_y_path_regex):\n",
    "    # read & merge Y data\n",
    "    data_y_paths = glob.glob(data_y_path_regex)\n",
    "    print(\"CSV found:\")\n",
    "    for data_y_path in data_y_paths:\n",
    "        print(f\"    {data_y_path}\") \n",
    "\n",
    "    assert data_y_paths.__len__() > 0\n",
    "    dy_full = pd.concat([pd.read_csv(data_y_path) for data_y_path in data_y_paths])\n",
    "\n",
    "    # todo: filter out nulls\n",
    "    dy = dy_full\n",
    "\n",
    "    # filter out samples & labels of fewer than 2 positive\n",
    "    labels_cls_too_few = dy[labels_cls].loc[:, (dy[labels_cls].sum() < 2)].columns\n",
    "    for label_cls_too_few in labels_cls_too_few:\n",
    "        dy = dy.drop(dy[dy.loc[:, label_cls_too_few] == 1].index, axis=0)\n",
    "    dy = dy.drop(labels_cls_too_few, axis=1)\n",
    "    dl = [label_cls for label_cls in labels_cls if label_cls not in labels_cls_too_few]\n",
    "\n",
    "    # read & filter_out by Y & map X data\n",
    "    data_x_paths = glob.glob(data_x_path_regex)\n",
    "    data_x_paths = [dxp.replace('\\\\', '/') for dxp in data_x_paths]\n",
    "    map_ref2path_full = {ref: next((dxp for dxp in data_x_paths if ref in dxp), None) for ref in dy_full[label_x_ref]}\n",
    "    map_ref2path = {ref: data_x_path for ref, data_x_path in map_ref2path_full.items() if (ref == dy[label_x_ref]).any() and data_x_path is not None}\n",
    "    # dx = {ref: data_x_loader(data_x_path) for ref, data_x_path in map_ref2path.items()}\n",
    "\n",
    "    # filter out Y entries that dont have X entry\n",
    "    dy = dy.loc[dy[label_x_ref].isin(map_ref2path.keys())]\n",
    "\n",
    "    # add path column\n",
    "    paths = [map_ref2path[ref] for ref in dy[label_x_ref]]\n",
    "    dy[label_x_path] = paths\n",
    "\n",
    "    # add sparse & categorical classification column\n",
    "    dy[label_y_sparse] = dy[dl].to_numpy().argmax(axis=1)\n",
    "    dy[label_y_cat] = [dl[y_spar] for y_spar in dy[label_y_sparse]]\n",
    "\n",
    "    print(\n",
    "    f\"\"\"Read stats:\n",
    "    # entries ok: {dy.__len__()}\n",
    "    # excess X: {map_ref2path_full.__len__() - map_ref2path.__len__()}\n",
    "    # excess Y: {dy_full.__len__() - dy.__len__()}\n",
    "    # excess L: {labels_cls_too_few.__len__()}  \"\"\") # e.L- Labels of too little samples\n",
    "\n",
    "    print(\"# samples/label:\")\n",
    "    print(dy[dl].sum(axis=0).astype(int), end=\"\\t\\n\")\n",
    "    return None, dy, dl\n",
    "\n",
    "_, dy, dl = load(data_x_path_regex, data_y_path_regex)\n",
    "dy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#draft\n",
    "# dy[dl].to_numpy().argmax(axis=1)\n",
    "# \"aaa\".replace()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAIN TEST SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelBinarizer\n",
    "\n",
    "tts_factor = .2\n",
    "\n",
    "# ohe = OneHotEncoder(sparse_output=False)\n",
    "# ohe.fit(np.reshape(dl, (-1, 1)))\n",
    "# dy_sparse = ohe.inverse_transform()\n",
    "\n",
    "dyt, dyv = train_test_split(dy, test_size=tts_factor, stratify=dy[dl].to_numpy().argmax(axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def d2cd(dx, dy_selected, dl): \n",
    "#     \"\"\"data to cassification data (dx, dy, dl -> cdx: numpy.ndarray[n, y, x, c], cdy: numpy.ndarray[n, l])\"\"\"\n",
    "#     return (np.asarray([dx[x_ref] for x_ref in dy_selected[label_x_ref]]), dy_selected[dl].to_numpy())\n",
    "\n",
    "# cdxt, cdyt = d2cd(dx, dyt, dl)\n",
    "# cdxv, cdyv = d2cd(dx, dyv, dl)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN (control case; src: ex s9/DNN/lab4)\n",
    "\n",
    "% coś slabo mi się uczy ale pewnie danych mao\n",
    "\n",
    "params:\n",
    "* `batch_size`\n",
    "* `model.fit(epochs=)`\n",
    "* `flatten_res_max` - do jakiego rozmiaru konwolucja ma zredukować obraz (żeby nie narobiło parametrów)\n",
    "\n",
    "args:\n",
    "* `(cdx*, cdy*, dl)`\n",
    "\n",
    "output:\n",
    "* `model: clf` \n",
    "* `history: keras.callbacks.History`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import tensorflow as tf\n",
    "# tf.config.list_physical_devices('GPU')\n",
    "\n",
    "from keras import backend\n",
    "backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_1 (Rescaling)     (None, 600, 450, 3)       0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 598, 448, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 299, 224, 32)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 297, 222, 56)      16184     \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 148, 111, 56)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 146, 109, 80)      40400     \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 73, 54, 80)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 71, 52, 104)       74984     \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 35, 26, 104)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 33, 24, 128)       119936    \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 16, 12, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 24576)             0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 24576)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 256)               6291712   \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 7)                 1799      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,545,911\n",
      "Trainable params: 6,545,911\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# # os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from keras.preprocessing import image\n",
    "\n",
    "batch_size = 16\n",
    "flatten_res_max = 200  \n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Rescaling(1./255, 0., input_shape=data_x_target_shape))\n",
    "\n",
    "conv_converg  = lambda cr: (((cr[0]-2) // 2), (cr[1]-2)//2)\n",
    "step_channels = 1\n",
    "conv_redo = data_x_target_res\n",
    "while (conv_redo := conv_converg(conv_redo)) and conv_redo[0]*conv_redo[1] > flatten_res_max:\n",
    "    step_channels += 1\n",
    "\n",
    "for n_channels in np.linspace(32, 128, step_channels):\n",
    "    model.add(layers.Conv2D(n_channels, (3,)*2, activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2,)*2))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(len(dl), activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(learning_rate=1e-4),\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8012 validated image filenames.\n",
      "Found 0 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = image.ImageDataGenerator(\n",
    "      rescale=1./255,\n",
    "      rotation_range=40,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      shear_range=0.2,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest',\n",
    "#       validation_split=.2\n",
    ")\n",
    "# train_datagen.fit(cdxt) #, augment=True, rounds=rounds)\n",
    "# train_flow = train_datagen.flow(\n",
    "#         cdxt, cdyt,\n",
    "#         batch_size=batch_size,\n",
    "# )\n",
    "train_generator=train_datagen.flow_from_dataframe(\n",
    "      dataframe=dyt,\n",
    "      directory=\".\",\n",
    "      x_col=label_x_path,\n",
    "      y_col=dl,\n",
    "      subset=\"training\",\n",
    "      batch_size=32,\n",
    "      # seed=42,\n",
    "      shuffle=True,\n",
    "      class_mode=\"raw\",\n",
    "      target_size=data_x_target_res,\n",
    ")\n",
    "\n",
    "val_datagen = image.ImageDataGenerator(rescale=1./255)\n",
    "# val_datagen.fit(cdxv)\n",
    "# val_flow = val_datagen.flow(\n",
    "#         cdxv, cdyv,\n",
    "#         batch_size=batch_size,\n",
    "# )\n",
    "val_generator=val_datagen.flow_from_dataframe(\n",
    "      dataframe=dyv,\n",
    "      directory=\".\",\n",
    "      x_col=label_x_path,\n",
    "      y_col=dl,\n",
    "      subset=\"validation\",\n",
    "      batch_size=32,\n",
    "      # seed=42,\n",
    "      shuffle=True,\n",
    "      class_mode=\"raw\",\n",
    "      target_size=data_x_target_res,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/30 [=========>....................] - ETA: 2:07 - loss: 1.9063 - accuracy: 0.6250"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# # Train\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m      3\u001b[0m       train_generator,\n\u001b[0;32m      4\u001b[0m       steps_per_epoch\u001b[39m=\u001b[39;49m\u001b[39m30\u001b[39;49m,\n\u001b[0;32m      5\u001b[0m       epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m,\n\u001b[0;32m      6\u001b[0m       validation_data\u001b[39m=\u001b[39;49mval_generator,\n\u001b[0;32m      7\u001b[0m     \u001b[39m#   validation_steps=len(val_flow)\u001b[39;49;00m\n\u001b[0;32m      8\u001b[0m ) \u001b[39m#verbose=2)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\krism\\Desktop\\semestr10\\IO\\pvio\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\krism\\Desktop\\semestr10\\IO\\pvio\\lib\\site-packages\\keras\\engine\\training.py:1685\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1677\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1678\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1679\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1682\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1683\u001b[0m ):\n\u001b[0;32m   1684\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1685\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1686\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1687\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\krism\\Desktop\\semestr10\\IO\\pvio\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\krism\\Desktop\\semestr10\\IO\\pvio\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    891\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    893\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 894\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    896\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    897\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\krism\\Desktop\\semestr10\\IO\\pvio\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:926\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    923\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    924\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    925\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 926\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_no_variable_creation_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    927\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    928\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    929\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    930\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\krism\\Desktop\\semestr10\\IO\\pvio\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    141\u001b[0m   (concrete_function,\n\u001b[0;32m    142\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 143\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m    144\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\krism\\Desktop\\semestr10\\IO\\pvio\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1753\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1754\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1755\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1756\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1757\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1758\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1759\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1760\u001b[0m     args,\n\u001b[0;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1762\u001b[0m     executing_eagerly)\n\u001b[0;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\krism\\Desktop\\semestr10\\IO\\pvio\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    380\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 381\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    382\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    383\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    384\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    385\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    386\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    387\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    388\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    389\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    390\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    393\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    394\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\krism\\Desktop\\semestr10\\IO\\pvio\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# # Train\n",
    "history = model.fit(\n",
    "      train_generator,\n",
    "      steps_per_epoch=30,\n",
    "      epochs=10,\n",
    "      validation_data=val_generator,\n",
    "    #   validation_steps=len(val_flow)\n",
    ") #verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$(getFreeGPU)\n"
     ]
    }
   ],
   "source": [
    "! echo $(getFreeGPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>MEL</th>\n",
       "      <th>NV</th>\n",
       "      <th>BCC</th>\n",
       "      <th>AKIEC</th>\n",
       "      <th>BKL</th>\n",
       "      <th>DF</th>\n",
       "      <th>VASC</th>\n",
       "      <th>path</th>\n",
       "      <th>sparse</th>\n",
       "      <th>categorical</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2325</th>\n",
       "      <td>ISIC_0026631</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>../ISIC2018_Task3_Training_Input/ISIC_0026631.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>BKL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5699</th>\n",
       "      <td>ISIC_0030005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>../ISIC2018_Task3_Training_Input/ISIC_0030005.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>BKL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1771</th>\n",
       "      <td>ISIC_0026077</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>../ISIC2018_Task3_Training_Input/ISIC_0026077.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>NV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3854</th>\n",
       "      <td>ISIC_0028160</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>../ISIC2018_Task3_Training_Input/ISIC_0028160.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>NV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811</th>\n",
       "      <td>ISIC_0025117</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>../ISIC2018_Task3_Training_Input/ISIC_0025117.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>NV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2784</th>\n",
       "      <td>ISIC_0027090</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>../ISIC2018_Task3_Training_Input/ISIC_0027090.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>BCC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1243</th>\n",
       "      <td>ISIC_0025549</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>../ISIC2018_Task3_Training_Input/ISIC_0025549.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>NV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6721</th>\n",
       "      <td>ISIC_0031027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>../ISIC2018_Task3_Training_Input/ISIC_0031027.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>NV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1904</th>\n",
       "      <td>ISIC_0026210</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>../ISIC2018_Task3_Training_Input/ISIC_0026210.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>NV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3498</th>\n",
       "      <td>ISIC_0027804</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>../ISIC2018_Task3_Training_Input/ISIC_0027804.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>NV</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8012 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             image  MEL   NV  BCC  AKIEC  BKL   DF  VASC  \\\n",
       "2325  ISIC_0026631  0.0  0.0  0.0    0.0  1.0  0.0   0.0   \n",
       "5699  ISIC_0030005  0.0  0.0  0.0    0.0  1.0  0.0   0.0   \n",
       "1771  ISIC_0026077  0.0  1.0  0.0    0.0  0.0  0.0   0.0   \n",
       "3854  ISIC_0028160  0.0  1.0  0.0    0.0  0.0  0.0   0.0   \n",
       "811   ISIC_0025117  0.0  1.0  0.0    0.0  0.0  0.0   0.0   \n",
       "...            ...  ...  ...  ...    ...  ...  ...   ...   \n",
       "2784  ISIC_0027090  0.0  0.0  1.0    0.0  0.0  0.0   0.0   \n",
       "1243  ISIC_0025549  0.0  1.0  0.0    0.0  0.0  0.0   0.0   \n",
       "6721  ISIC_0031027  0.0  1.0  0.0    0.0  0.0  0.0   0.0   \n",
       "1904  ISIC_0026210  0.0  1.0  0.0    0.0  0.0  0.0   0.0   \n",
       "3498  ISIC_0027804  0.0  1.0  0.0    0.0  0.0  0.0   0.0   \n",
       "\n",
       "                                                   path  sparse categorical  \n",
       "2325  ../ISIC2018_Task3_Training_Input/ISIC_0026631.jpg       4         BKL  \n",
       "5699  ../ISIC2018_Task3_Training_Input/ISIC_0030005.jpg       4         BKL  \n",
       "1771  ../ISIC2018_Task3_Training_Input/ISIC_0026077.jpg       1          NV  \n",
       "3854  ../ISIC2018_Task3_Training_Input/ISIC_0028160.jpg       1          NV  \n",
       "811   ../ISIC2018_Task3_Training_Input/ISIC_0025117.jpg       1          NV  \n",
       "...                                                 ...     ...         ...  \n",
       "2784  ../ISIC2018_Task3_Training_Input/ISIC_0027090.jpg       2         BCC  \n",
       "1243  ../ISIC2018_Task3_Training_Input/ISIC_0025549.jpg       1          NV  \n",
       "6721  ../ISIC2018_Task3_Training_Input/ISIC_0031027.jpg       1          NV  \n",
       "1904  ../ISIC2018_Task3_Training_Input/ISIC_0026210.jpg       1          NV  \n",
       "3498  ../ISIC2018_Task3_Training_Input/ISIC_0027804.jpg       1          NV  \n",
       "\n",
       "[8012 rows x 11 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dyt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DT CLASSIFIER\n",
    "% TBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dtc = DecisionTreeClassifier()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "METRICS\n",
    "%TBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# ohe.inverse_transform\n",
    "confusion_matrix(cdyv.argmax(axis=1), model.predict(cdxv.swapaxes(1,2)).argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Porównanie metryk uczenia\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 4))\n",
    "h = history.history\n",
    "\n",
    "ax[0].set_title('loss')\n",
    "ax[0].plot(h['loss'], label='train')\n",
    "ax[0].plot(h['val_loss'], label='val')\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].set_title('accuracy')\n",
    "ax[1].plot(h['accuracy'], label='train')\n",
    "ax[1].plot(h['val_accuracy'], label='val')\n",
    "ax[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 2s 275ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 98, 100,  59,   0,  99,   0],\n",
       "       [ 99, 100,  60,   0,  99,   0],\n",
       "       [ 99, 100,  60,   0,  99,   0],\n",
       "       [ 99, 100,  60,   0,  99,   0],\n",
       "       [ 99, 100,  59,   0,  99,   0],\n",
       "       [ 99, 100,  59,   0,  99,   0],\n",
       "       [ 98, 100,  58,   0,  99,   0],\n",
       "       [ 98, 100,  59,   0,  99,   0],\n",
       "       [ 98, 100,  59,   0,  99,   0],\n",
       "       [ 99, 100,  60,   0,  99,   0],\n",
       "       [ 99, 100,  60,   0,  99,   0],\n",
       "       [ 98, 100,  59,   0,  99,   0],\n",
       "       [ 98, 100,  59,   0,  99,   0],\n",
       "       [ 98, 100,  59,   0,  99,   0],\n",
       "       [ 98, 100,  59,   0,  99,   0],\n",
       "       [ 99, 100,  60,   0,  99,   0],\n",
       "       [ 98, 100,  59,   0,  99,   0],\n",
       "       [ 98, 100,  59,   0,  99,   0],\n",
       "       [ 99, 100,  59,   0,  99,   0],\n",
       "       [ 98, 100,  59,   0,  99,   0],\n",
       "       [ 98, 100,  59,   0,  99,   0],\n",
       "       [ 98, 100,  59,   0,  99,   0],\n",
       "       [ 98, 100,  59,   0,  99,   0],\n",
       "       [ 98, 100,  59,   0,  99,   0],\n",
       "       [ 99, 100,  60,   0,  99,   0],\n",
       "       [ 98, 100,  59,   0,  99,   0],\n",
       "       [ 98, 100,  59,   0,  99,   0],\n",
       "       [ 98, 100,  59,   0,  99,   0],\n",
       "       [ 99, 100,  59,   0,  99,   0],\n",
       "       [ 99, 100,  59,   0,  99,   0],\n",
       "       [ 98, 100,  59,   0,  99,   0],\n",
       "       [ 99, 100,  60,   0,  99,   0],\n",
       "       [ 98, 100,  59,   0,  99,   0],\n",
       "       [ 98, 100,  59,   0,  99,   0],\n",
       "       [ 98, 100,  59,   0,  99,   0],\n",
       "       [ 99, 100,  59,   0,  99,   0],\n",
       "       [ 99, 100,  60,   0,  99,   0],\n",
       "       [ 98, 100,  59,   0,  99,   0],\n",
       "       [ 98, 100,  59,   0,  99,   0]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ohe.fit([[label_cls, lix] for lix, label_cls in enumerate(labels_cls)])\n",
    "# ohe.fit_transform(labels_cls)\n",
    "# print(ohe.get_feature_names_out())\n",
    "\n",
    "# [y for y in dy['image']]\n",
    "# data_x_paths\n",
    "# dy.at[8, 'DF'] = dx[1]\n",
    "# np.where(dy['image'][0] in data_x_paths)\n",
    "# for a, in map(str.__contains__, dy['image'], data_x_paths):\n",
    "#     print(a) \n",
    "# dy.loc[dy['image'].isin(['ISIC_0034321', ''])]\n",
    "# map_ref2path.keys()\n",
    "# dx\n",
    "# import keras\n",
    "# sparse_encode([[0, 1], [1, 0]])\n",
    "\n",
    "# from sklearn.decomposition import sparse_encode\n",
    "# ohe.inverse_transform(dy[labels_cls].to_numpy())\n",
    "# ohe.transform(ohe.inverse_transform(dy[labels_cls]))\n",
    "# dy[labels_cls].loc[:, (dy[labels_cls].sum() < 2)].columns\n",
    "# dy.loc[dy['DF'] == 1]\n",
    "# dy.drop\n",
    "# dy.drop(dy[dy.loc[:, 'DF'] == 1].index, axis=0).__len__()\n",
    "# dy.loc[dy[['DF']] == 1]\n",
    "# (\"ISIC_0034321\" == dy['image']).any()\n",
    "\n",
    "# for i in range(30):\n",
    "#     print(i, next(train_flow)[0].shape)\n",
    "# # train_flow.n\n",
    "# print(len(train_flow), rounds)\n",
    "# image.ImageDataGenerator()\n",
    "\n",
    "# from tensorflow.keras.applications import VGG16\n",
    " \n",
    "# conv_base = VGG16(weights='imagenet',\n",
    "#                   include_top=False,\n",
    "#                   input_shape=data_x_target_res)\n",
    "\n",
    "# conv_base.trainable = False\n",
    "\n",
    "# # Zintegrowanie sicei VGG16 oraz nowego klasyfikatora\n",
    "# model = models.Sequential()\n",
    "# model.add(conv_base)\n",
    "# model.add(layers.Flatten())\n",
    "# model.add(layers.Dense(256, activation='relu'))\n",
    "# model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# model.compile(loss='binary_crossentropy',\n",
    "#               optimizer=optimizers.RMSprop(learning_rate=2e-5),\n",
    "#               metrics=['acc'])\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "# model.add(layers.Conv2D(32, (3,)*2, activation='relu'))\n",
    "# model.add(layers.MaxPooling2D((2,)*2))\n",
    "# model.add(layers.Conv2D(32, (3,)*2, activation='relu'))\n",
    "# model.add(layers.MaxPooling2D((2,)*2))\n",
    "# model.add(layers.Conv2D(64, (3,)*2, activation='relu'))\n",
    "# model.add(layers.MaxPooling2D((2,)*2))\n",
    "# model.add(layers.Conv2D(64, (3,)*2, activation='relu'))\n",
    "# model.add(layers.MaxPooling2D((2,)*2))\n",
    "# model.add(layers.Conv2D(128, (3,)*2, activation='relu'))\n",
    "# model.add(layers.MaxPooling2D((2,)*2))\n",
    "# model.add(layers.Conv2D(128, (3,)*2, activation='relu'))\n",
    "# model.add(layers.MaxPooling2D((2,)*2))\n",
    "\n",
    "# history\n",
    "# for i in range(10):\n",
    "#     print(cdxt[i, 0, 0, :], cdyt[i])\n",
    "(model.predict(cdxv.swapaxes(1,2))*100).astype(int)\n",
    "# cdyt.sum(axis=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
